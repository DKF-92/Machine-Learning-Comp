{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wine Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports libraries/ect..\n",
    "import numpy as np                  \n",
    "import pandas as pd                 \n",
    "import matplotlib.pyplot as plt     \n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression, RidgeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "seed = 7\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "sns.set_theme()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"WineQT.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drops unneeded ID column\n",
    "df = df.drop(['Id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finds na values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looks for duplicates\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drops duplicates\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(12,2, figsize=(30,80))\n",
    "for index, i in enumerate(df.columns):\n",
    "    sns.distplot(df[i], ax=ax[index,0],color='blue')\n",
    "    stats.probplot(df[i], plot=ax[index,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation of features\n",
    "mat = df.corr()\n",
    "fig, ax = plt.subplots(figsize = (15,15))\n",
    "sns.heatmap(mat, annot = True, annot_kws={'size': 15});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plots for outliers\n",
    "fig, ax = plt.subplots(3, 1, figsize=(12, 18))\n",
    "\n",
    "sns.boxplot(data=df[df.columns[0:4]], ax=ax[0])\n",
    "sns.boxplot(data=df[df.columns[4:8]], ax=ax[1])\n",
    "sns.boxplot(data=df[df.columns[8:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finds outliers based on z_score then removes them\n",
    "def outlier_dect(df, column):\n",
    "    z_scores = np.abs(stats.zscore(df[column]))\n",
    "    df = df[(z_scores < 3)]\n",
    "    print(column, \" = \", len(np.where(z_scores>3)[0]), 'outliers')\n",
    "    return df\n",
    "\n",
    "# Run for columns\n",
    "for column in df.columns:\n",
    "    df = outlier_dect(df, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plots for after outliers detection\n",
    "fig, ax = plt.subplots(3, 1, figsize=(12, 18))\n",
    "\n",
    "sns.boxplot(data=df[df.columns[0:4]], ax=ax[0])\n",
    "sns.boxplot(data=df[df.columns[4:8]], ax=ax[1])\n",
    "sns.boxplot(data=df[df.columns[8:]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Prepping and Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigns data to X and y\n",
    "X = df.drop(['quality'], axis=1)\n",
    "y = df['quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits data test shape\n",
    "X_train, X_val, y_train, y_val = train_test_split(X,y,test_size=0.2,random_state=11)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)\n",
    "\n",
    "df.sample(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Normalized Data Models  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras Neural Network Model\n",
    "def create_model():\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Input(shape=(11,)))\n",
    "    model.add(tf.keras.layers.Dense(128))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(tf.keras.layers.Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(tf.keras.layers.Dense(32))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    model.compile(optimizer = tf.optimizers.Adam(), loss = 'binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a function to train models, this can be repurposed for Normailized data\n",
    "\n",
    "def train_models(X_train, y_train, X_val, y_val, print_acc=False):\n",
    "\n",
    "    dict_acc = {}\n",
    "\n",
    "    # Label Encoder: this will allow XGBoost to preform as y_train/y_val will start from 0\n",
    "    # previous error: ValueError: Invalid classes inferred from unique values of `y`. Expected: [0 1 2 3 4], got [4 5 6 7 8] (XGB model)\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    le = LabelEncoder()\n",
    "    y_train = le.fit_transform(y_train)\n",
    "    y_val = le.fit_transform(y_val)\n",
    "\n",
    "\n",
    "    # Dummy classifier to test if models can make good fit\n",
    "    dum = DummyClassifier(strategy='prior')\n",
    "\n",
    "    scores = cross_val_score(dum, X_train, y_train, cv=kfold, scoring='accuracy')\n",
    "    acc_dum_train = scores.mean()\n",
    "    dum.fit(X_train, y_train)\n",
    "    acc_dum_val = dum.score(X_val, y_val)\n",
    "\n",
    "    dict_acc['Dummy Classifier'] = [acc_dum_train, acc_dum_val]\n",
    "\n",
    "    # Bernoulli Naive Bayes\n",
    "    bern = BernoulliNB()\n",
    "\n",
    "    scores = cross_val_score(bern, X_train, y_train, cv=kfold, scoring='accuracy')\n",
    "    acc_bern_train = scores.mean()\n",
    "    bern.fit(X_train, y_train)\n",
    "    acc_bern_val = bern.score(X_val, y_val)\n",
    "\n",
    "    dict_acc['Bernoulli NB'] = [acc_bern_train, acc_bern_val]\n",
    "\n",
    "    # Decision Tree\n",
    "    dtree = DecisionTreeClassifier()\n",
    "\n",
    "    scores = cross_val_score(dtree, X_train, y_train, cv=kfold, scoring='accuracy')\n",
    "    acc_dtree_train = scores.mean()\n",
    "    dtree.fit(X_train, y_train)\n",
    "    acc_dtree_val = dtree.score(X_val, y_val)\n",
    "\n",
    "    dict_acc['Decision Tree'] = [acc_dtree_train, acc_dtree_val]\n",
    "\n",
    "    #Ridge Classifer\n",
    "    rclass = RidgeClassifier()\n",
    "\n",
    "    scores = cross_val_score(rclass, X_train, y_train, cv=kfold, scoring='accuracy')\n",
    "    acc_rclass_train = scores.mean()\n",
    "    rclass.fit(X_train, y_train)\n",
    "    acc_rclass_val = rclass.score(X_val, y_val)\n",
    "\n",
    "    dict_acc['Ridge Classifier'] = [acc_rclass_train, acc_rclass_val]\n",
    "\n",
    "    #Logistic Regression\n",
    "    lr = LogisticRegression()\n",
    "\n",
    "    scores = cross_val_score(lr, X_train, y_train, cv=kfold, scoring='accuracy')\n",
    "    acc_lr_train = scores.mean()\n",
    "    lr.fit(X_train, y_train)\n",
    "    acc_lr_val = lr.score(X_val, y_val)\n",
    "\n",
    "    dict_acc['Logistic Regression'] = [acc_lr_train, acc_lr_val]\n",
    "\n",
    "    # SGD Classifier\n",
    "    sgd = SGDClassifier()\n",
    "\n",
    "    scores = cross_val_score(sgd, X_train, y_train, cv=kfold, scoring='accuracy')\n",
    "    acc_sgd_train = scores.mean()\n",
    "    sgd.fit(X_train, y_train)\n",
    "    acc_sgd_val = sgd.score(X_val, y_val)\n",
    "\n",
    "    dict_acc['SGD Classifier'] = [acc_sgd_train, acc_sgd_val]\n",
    "\n",
    "    #KNeighborsClassifier\n",
    "    knn = KNeighborsClassifier()\n",
    "\n",
    "    scores = cross_val_score(knn, X_train, y_train, cv=kfold, scoring='accuracy')\n",
    "    acc_knn_train = scores.mean()\n",
    "    knn.fit(X_train, y_train)\n",
    "    acc_knn_val = knn.score(X_val, y_val)\n",
    "\n",
    "    dict_acc['KNeighbors Classifier'] = [acc_knn_train, acc_knn_val]\n",
    "\n",
    "    #Support Vector Classifier (SVC)\n",
    "    svc = SVC()\n",
    "\n",
    "    scores = cross_val_score(svc, X_train, y_train, cv=kfold, scoring='accuracy')\n",
    "    acc_svc_train = scores.mean()\n",
    "    svc.fit(X_train, y_train)\n",
    "    acc_svc_val = svc.score(X_val, y_val)\n",
    "\n",
    "    dict_acc['SVC'] = [acc_svc_train, acc_svc_val]\n",
    "\n",
    "    #Random Forest Classifier\n",
    "    rf = RandomForestClassifier()\n",
    "\n",
    "    scores = cross_val_score(rf, X_train, y_train, cv=kfold, scoring='accuracy')\n",
    "    acc_rf_train = scores.mean()\n",
    "    rf.fit(X_train, y_train)\n",
    "    acc_rf_val = rf.score(X_val, y_val)\n",
    "\n",
    "    dict_acc['Random Forest Classifier'] = [acc_rf_train, acc_rf_val]\n",
    "\n",
    "    #XGBClassifier\n",
    "    xgb = XGBClassifier()\n",
    "\n",
    "    scores = cross_val_score(xgb, X_train, y_train, cv=kfold, scoring='accuracy')\n",
    "    acc_xgb_train = scores.mean()\n",
    "    xgb.fit(X_train, y_train)\n",
    "    acc_xgb_val = xgb.score(X_val, y_val)\n",
    "\n",
    "    dict_acc['XGBoost Classifier'] = [acc_xgb_train, acc_xgb_val]\n",
    "\n",
    "    #Neural Network\n",
    "    model_keras = KerasClassifier(build_fn=create_model, epochs=150, batch_size=64, verbose=0)\n",
    "\n",
    "    results = cross_val_score(model_keras, X_train, y_train, cv=kfold)\n",
    "    acc_train = results.mean()\n",
    "    model_keras.fit(X_train, y_train)\n",
    "    acc_keras = model_keras.score(X_val, y_val)\n",
    "\n",
    "    dict_acc['Neural Network'] = [acc_train, acc_keras]\n",
    "\n",
    "    # Printing the values\n",
    "    if print_acc:\n",
    "        for key, values in dict_acc.items():\n",
    "            print(\"{} Accuracy on Training Data (CV): {}\".format(key, values[0]))\n",
    "            print(\"{} Accuracy on Validation Data: {}\".format(key, values[1]))\n",
    "            print()\n",
    "    \n",
    "    return dict_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_models = train_models(X_train, y_train, X_val, y_val, print_acc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_acc = pd.DataFrame.from_dict(dict_models)\n",
    "df_acc = df_acc.transpose()\n",
    "df_acc.columns = ['Acc Training (CV)', 'Acc Validation']\n",
    "df_acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
